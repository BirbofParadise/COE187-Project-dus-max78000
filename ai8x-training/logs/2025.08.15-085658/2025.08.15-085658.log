2025-08-15 08:56:58,978 - Log file for this run: D:\B_School\School\TestMax\ai8x-training\logs\2025.08.15-085658\2025.08.15-085658.log
2025-08-15 08:56:59,351 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2025-08-15 08:56:59,352 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2025-08-15 08:56:59,713 - Dataset sizes:
	training=72000
	validation=8000
	test=5000
2025-08-15 08:56:59,713 - Reading compression schedule from: policies/schedule-catsdogs.yaml
2025-08-15 08:56:59,717 - 

2025-08-15 08:56:59,719 - Training epoch: 72000 samples (256 per mini-batch)
2025-08-15 09:07:14,618 - Epoch: [0][  282/  282]    Overall Loss 0.592076    Objective Loss 0.592076    Top1 69.687500    LR 0.001000    Time 2.180439    
2025-08-15 09:07:15,328 - --- validate (epoch=0)-----------
2025-08-15 09:07:15,329 - 8000 samples (256 per mini-batch)
2025-08-15 09:07:56,043 - Epoch: [0][   32/   32]    Loss 0.512035    Top1 74.350000    
2025-08-15 09:07:56,922 - ==> Top1: 74.350    Loss: 0.512

2025-08-15 09:07:56,923 - ==> Confusion:
[[2854 1027]
 [1025 3094]]

2025-08-15 09:07:57,039 - ==> Best [Top1: 74.350   Sparsity:0.00   Params: 57776 on epoch: 0]
2025-08-15 09:07:57,040 - Saving checkpoint to: logs\2025.08.15-085658\checkpoint.pth.tar
2025-08-15 09:07:57,063 - 

2025-08-15 09:07:57,063 - Training epoch: 72000 samples (256 per mini-batch)
2025-08-15 09:17:05,876 - Epoch: [1][  282/  282]    Overall Loss 0.474959    Objective Loss 0.474959    Top1 82.187500    LR 0.001000    Time 1.946116    
2025-08-15 09:17:06,665 - --- validate (epoch=1)-----------
2025-08-15 09:17:06,666 - 8000 samples (256 per mini-batch)
2025-08-15 09:17:45,411 - Epoch: [1][   32/   32]    Loss 0.446476    Top1 78.687500    
2025-08-15 09:17:46,238 - ==> Top1: 78.688    Loss: 0.446

2025-08-15 09:17:46,239 - ==> Confusion:
[[3451  430]
 [1275 2844]]

2025-08-15 09:17:46,307 - ==> Best [Top1: 78.688   Sparsity:0.00   Params: 57776 on epoch: 1]
2025-08-15 09:17:46,307 - Saving checkpoint to: logs\2025.08.15-085658\checkpoint.pth.tar
2025-08-15 09:17:46,331 - 

2025-08-15 09:17:46,331 - Training epoch: 72000 samples (256 per mini-batch)
2025-08-15 09:27:24,862 - Epoch: [2][  282/  282]    Overall Loss 0.404898    Objective Loss 0.404898    Top1 82.187500    LR 0.001000    Time 2.051464    
2025-08-15 09:27:25,693 - --- validate (epoch=2)-----------
2025-08-15 09:27:25,694 - 8000 samples (256 per mini-batch)
2025-08-15 09:28:06,651 - Epoch: [2][   32/   32]    Loss 0.375699    Top1 83.500000    
2025-08-15 09:28:07,474 - ==> Top1: 83.500    Loss: 0.376

2025-08-15 09:28:07,474 - ==> Confusion:
[[3167  714]
 [ 606 3513]]

2025-08-15 09:28:07,544 - ==> Best [Top1: 83.500   Sparsity:0.00   Params: 57776 on epoch: 2]
2025-08-15 09:28:07,544 - Saving checkpoint to: logs\2025.08.15-085658\checkpoint.pth.tar
2025-08-15 09:28:07,572 - 

2025-08-15 09:28:07,572 - Training epoch: 72000 samples (256 per mini-batch)
2025-08-15 09:37:18,097 - Epoch: [3][  282/  282]    Overall Loss 0.350878    Objective Loss 0.350878    Top1 85.937500    LR 0.001000    Time 1.952161    
2025-08-15 09:37:18,774 - --- validate (epoch=3)-----------
2025-08-15 09:37:18,775 - 8000 samples (256 per mini-batch)
2025-08-15 09:37:57,372 - Epoch: [3][   32/   32]    Loss 0.329219    Top1 85.537500    
2025-08-15 09:37:58,174 - ==> Top1: 85.537    Loss: 0.329

2025-08-15 09:37:58,175 - ==> Confusion:
[[3238  643]
 [ 514 3605]]

2025-08-15 09:37:58,244 - ==> Best [Top1: 85.537   Sparsity:0.00   Params: 57776 on epoch: 3]
2025-08-15 09:37:58,244 - Saving checkpoint to: logs\2025.08.15-085658\checkpoint.pth.tar
2025-08-15 09:37:58,266 - 

2025-08-15 09:37:58,268 - Training epoch: 72000 samples (256 per mini-batch)
2025-08-15 09:47:15,045 - Epoch: [4][  282/  282]    Overall Loss 0.304172    Objective Loss 0.304172    Top1 83.437500    LR 0.001000    Time 1.974373    
2025-08-15 09:47:15,667 - --- validate (epoch=4)-----------
2025-08-15 09:47:15,667 - 8000 samples (256 per mini-batch)
2025-08-15 09:47:56,072 - Epoch: [4][   32/   32]    Loss 0.306787    Top1 86.700000    
2025-08-15 09:47:56,912 - ==> Top1: 86.700    Loss: 0.307

2025-08-15 09:47:56,912 - ==> Confusion:
[[3228  653]
 [ 411 3708]]

2025-08-15 09:47:56,975 - ==> Best [Top1: 86.700   Sparsity:0.00   Params: 57776 on epoch: 4]
2025-08-15 09:47:56,975 - Saving checkpoint to: logs\2025.08.15-085658\checkpoint.pth.tar
2025-08-15 09:47:56,995 - --- test ---------------------
2025-08-15 09:47:56,995 - 5000 samples (256 per mini-batch)
2025-08-15 09:48:35,670 - Test: [   20/   20]    Loss 0.297177    Top1 87.100000    
2025-08-15 09:48:36,238 - ==> Top1: 87.100    Loss: 0.297

2025-08-15 09:48:36,238 - ==> Confusion:
[[2055  445]
 [ 200 2300]]

2025-08-15 09:48:36,258 - 
2025-08-15 09:48:36,259 - Log file for this run: D:\B_School\School\TestMax\ai8x-training\logs\2025.08.15-085658\2025.08.15-085658.log
