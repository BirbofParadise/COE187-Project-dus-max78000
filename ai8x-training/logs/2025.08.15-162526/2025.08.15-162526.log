2025-08-15 16:25:26,733 - Log file for this run: D:\B_School\School\TestMax\ai8x-training\logs\2025.08.15-162526\2025.08.15-162526.log
2025-08-15 16:25:27,133 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2025-08-15 16:25:27,133 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2025-08-15 16:56:36,817 - Dataset sizes:
	training=101719
	validation=11302
	test=13430
2025-08-15 16:56:36,829 - Reading compression schedule from: policies/schedule_kws20.yaml
2025-08-15 16:56:36,911 - 

2025-08-15 16:56:36,919 - Training epoch: 101719 samples (256 per mini-batch)
2025-08-15 16:59:50,242 - Epoch: [0][  398/  398]    Overall Loss 2.206534    Objective Loss 2.206534    Top1 40.524781    Top5 78.134111    LR 0.001000    Time 0.485698    
2025-08-15 16:59:51,097 - --- validate (epoch=0)-----------
2025-08-15 16:59:51,097 - 11302 samples (256 per mini-batch)
2025-08-15 17:00:18,465 - Epoch: [0][   45/   45]    Loss 1.561675    Top1 44.293045    Top5 77.782693    
2025-08-15 17:00:19,245 - ==> Top1: 44.293    Top5: 77.783    Loss: 1.562

2025-08-15 17:00:19,249 - ==> Confusion:
[[ 225    2    0    1   17    0    0    0    2   27    0    0    0    2    2   26    3    1    0    0    4]
 [   0  175    3   10    7    9    2   12   22    2   33    0    1   13   17    1   23    1   36    2    4]
 [   8    1   68    9   20   13  141   49    0    6    0    3    0    2    1   11    0    1    0   10    2]
 [   2   11    4  163    8   27    6   41    3    2   11    1    1    4   19   10    5    1    6    1    2]
 [  66    5    1    3  154    7    0    2    3   56    0    3    1   17   15   26    7    4    0    0    6]
 [   2   37    1   30    4   92    6   36    2    0    6   13    6   33   12    6    6    8    2    9    6]
 [   1    3   28    2    4    8  218   34    0    0    0    3    0    5    0   18    0    1    0    5    4]
 [   1    6    3   20    6   21   19  230    0    1   13    9    0    3    3    3    1    1   15   14    4]
 [   5    5    0    0    1    1    0    0  242   12    4    1    4    0   40    1   18    0    2    0   11]
 [  97    0    0    1   27    1    1    0    2  154    0    0    0    7   30   13    3    1    0    0    9]
 [   3   35    2   12    6   16    5   20   11    3  161    1    3    4   11    4   10    0   43    1    5]
 [   0    0    0    1    1   11    2    1    1    0    3  147   73   18    0   17   10   72    0    8    1]
 [   1    0    0    2    0    4    2    0    1    0    3   78  145    5    1    5   19   42    1    3    7]
 [   4    9    0    1   10   30    4    6    5    4    1    7    1  168   13    7   18    3    0   14    5]
 [  11   14    0    6    3    2    0    0   47   10    1    1    0    2  205    1   22    3    0    2    9]
 [  12    0    0    3   16    1    3    1    0    1    0   11    0    2    0  293    3   16    0    1    2]
 [   5   24    1    1    7    5    0    0   55    0    2    6    8   31   13   12  195    2    0    1    7]
 [   2    0    0    4    1    2    6    1    2    0    0   65   28    5    6   54   16  146    0    4    3]
 [   1   29    2   13    1    2    1   43    4    1   45    0    2    1    7    1    1    0  196    4    2]
 [   0    0    0    1    0    6    9   19    0    1    3   34    2   10    0    4    2    2    0  254    2]
 [ 213  247   32  112  151  128   44  217  111  132   84  103  108  196  238   95  263   90  128  304 1375]]

2025-08-15 17:00:19,954 - ==> Best [Top1: 44.293   Top5: 77.783   Sparsity:0.00   Params: 126490 on epoch: 0]
2025-08-15 17:00:19,954 - Saving checkpoint to: logs\2025.08.15-162526\checkpoint.pth.tar
2025-08-15 17:00:19,979 - 

2025-08-15 17:00:19,980 - Training epoch: 101719 samples (256 per mini-batch)
2025-08-15 17:02:53,270 - Epoch: [1][  398/  398]    Overall Loss 1.333526    Objective Loss 1.333526    Top1 57.434402    Top5 85.422741    LR 0.001000    Time 0.385106    
2025-08-15 17:02:53,917 - --- validate (epoch=1)-----------
2025-08-15 17:02:53,917 - 11302 samples (256 per mini-batch)
2025-08-15 17:03:15,108 - Epoch: [1][   45/   45]    Loss 1.122462    Top1 55.963546    Top5 87.090780    
2025-08-15 17:03:15,806 - ==> Top1: 55.964    Top5: 87.091    Loss: 1.122

2025-08-15 17:03:15,813 - ==> Confusion:
[[ 244    1    0    0   19    0    0    0    1   28    0    0    0    5    1    7    0    3    0    0    3]
 [   0  210    4    4   22    4    1    4   14    1   54    0    1    9    8    0   13    0   18    2    4]
 [   7    1  164    3   20    2  109   14    0    2    7    0    1    3    0    0    0    1    1    7    3]
 [   1    6   18  209   11    4    9    2    0    0   18    1    1    4   18    6    0    8    9    1    2]
 [   9    4    2    1  316    3    0    0    0    8    1    0    0    6    0   12    6    5    0    0    3]
 [   2   35   11   18   17   93   13   19    0    0   27    9    4   34    9    4    3    2    0    9    8]
 [   1    2   21    1    4    1  282    3    0    0    3    0    0    1    0    9    0    0    0    3    3]
 [   2    2   26    4    5   11   17  217    0    3   23    0    1    3    4    0    0    2   37   13    3]
 [  12    7    0    0    3    0    0    0  265   13    6    0    2    5   21    1    6    2    0    1    3]
 [ 110    0    4    0   18    0    1    0    5  181    0    0    0   11    9    4    0    0    0    0    3]
 [   2   17    9    7   16    7    6    8   11    2  242    0    1    2    5    0    1    0   15    0    5]
 [   2    0    1    3    2    6    1    1    1    0    5  162   86   19    0   20    4   34    0   12    7]
 [   2    2    0    1    2    1    1    0    3    0    7   54  175    5    0    7   11   43    0    1    4]
 [   6    3    3    1    9    6    5    1    4    7    3    5    1  212    2    5   10    1    0   18    8]
 [  10    6    0    3   16    1    0    0   32   13    2    0    2    3  231    0    8    3    0    2    7]
 [   2    1    2    1   16    0    7    0    0    0    0    3    1    0    1  309    1   18    0    1    2]
 [   7    9    1    0   25    0    0    0    6    1    2    3    6   18    1    8  282    1    0    0    5]
 [   2    0    0    3    1    0    3    1    2    0    2   17   34    1    8   27    2  238    0    0    4]
 [   2   17    3   12    3    1    2   20    5    0   48    0    0    1    6    1    0    0  232    2    1]
 [   1    0    1    0    0    3   14    7    0    1    2   16    7   11    0    4    2    4    1  271    4]
 [ 219  199   74  105  241   98   56   89   78   96  135   65  131  187  163   73  145  116  108  203 1790]]

2025-08-15 17:03:16,258 - ==> Best [Top1: 55.964   Top5: 87.091   Sparsity:0.00   Params: 126490 on epoch: 1]
2025-08-15 17:03:16,258 - Saving checkpoint to: logs\2025.08.15-162526\checkpoint.pth.tar
2025-08-15 17:03:16,288 - 

2025-08-15 17:03:16,289 - Training epoch: 101719 samples (256 per mini-batch)
2025-08-15 17:05:49,097 - Epoch: [2][  398/  398]    Overall Loss 1.018923    Objective Loss 1.018923    Top1 64.139942    Top5 92.711370    LR 0.001000    Time 0.383914    
2025-08-15 17:05:49,768 - --- validate (epoch=2)-----------
2025-08-15 17:05:49,768 - 11302 samples (256 per mini-batch)
2025-08-15 17:06:09,268 - Epoch: [2][   45/   45]    Loss 0.997828    Top1 59.281543    Top5 91.452840    
2025-08-15 17:06:09,877 - ==> Top1: 59.282    Top5: 91.453    Loss: 0.998

2025-08-15 17:06:09,884 - ==> Confusion:
[[ 253    0    2    0    2    0    0    0    9   32    0    0    0    3    1    1    1    5    1    0    2]
 [   0  195    2    7    7   17    0    3   21    1   60    1    4   12   16    0    7    1   11    1    7]
 [   7    0  240   11    5    3   31    8    0    5   11    0    3    7    0    2    0    2    0    6    4]
 [   0    5   12  231    2   10    0    1    1    1   19    0    3    2   18    3    0   17    2    0    1]
 [   8    2    2    0  321    2    0    0    1    4    2    0    0    7    4    9    3    6    0    0    5]
 [   1   23    8   17    8  130    2   10    1    1   10    3   15   48    9    0    2   10    0    8   11]
 [   0    0   24    4    0    2  277    0    0    2    3    0    0    0    0    7    0    2    0    4    9]
 [   4    2   27   11    2   37    9  194    1    1   19    3   11    3    1    0    0    3   31   12    2]
 [  13    5    0    0    0    1    0    0  277    7    4    0    8    5   19    0    0    4    0    0    4]
 [  92    0    3    0    2    0    3    1   19  197    0    1    1   10    7    3    1    2    0    0    4]
 [   3   11    2   18   10    8    3    1   13    2  263    0    2    5    5    0    0    0    6    0    4]
 [   1    0    0    1    1    5    0    0    0    0    1  115  124   13    0    8    2   83    0    7    5]
 [   1    1    0    2    1    1    0    0    1    2    0    8  215    0    1    3    4   77    0    0    2]
 [   6    2    2    1    3    7    0    0    5    5    1    6   10  238    3    2    6    2    0    6    5]
 [  12    1    0    2    2    1    0    0   31    6    0    1    2    1  258    0    1   13    0    2    6]
 [   2    0    0    2    9    0    3    0    0    2    0    3    3    0    2  299    1   36    0    1    2]
 [   4    5    1    1    8    1    1    0    4    0    2    4    8   14    0    5  304    5    0    0    8]
 [   2    0    1    2    0    0    0    0    1    1    0    2   14    0    3    2    1  315    0    0    1]
 [   2    9    3   13    0    2    0   19    4    0   78    0    4    1    6    0    0    2  210    0    3]
 [   1    1    0    0    0    4    2    3    0    0    2   25   11    8    0    2    2    6    0  278    4]
 [ 167  166   65  116   83  130   27   53   94  110  151   32  234  164  214   51   55  279   90  200 1890]]

2025-08-15 17:06:10,315 - ==> Best [Top1: 59.282   Top5: 91.453   Sparsity:0.00   Params: 126490 on epoch: 2]
2025-08-15 17:06:10,316 - Saving checkpoint to: logs\2025.08.15-162526\checkpoint.pth.tar
2025-08-15 17:06:10,341 - 

2025-08-15 17:06:10,342 - Training epoch: 101719 samples (256 per mini-batch)
2025-08-15 17:08:39,525 - Epoch: [3][  398/  398]    Overall Loss 0.862142    Objective Loss 0.862142    Top1 72.011662    Top5 95.043732    LR 0.001000    Time 0.374800    
2025-08-15 17:08:40,156 - --- validate (epoch=3)-----------
2025-08-15 17:08:40,156 - 11302 samples (256 per mini-batch)
2025-08-15 17:08:59,313 - Epoch: [3][   45/   45]    Loss 0.844595    Top1 66.236064    Top5 93.806406    
2025-08-15 17:08:59,906 - ==> Top1: 66.236    Top5: 93.806    Loss: 0.845

2025-08-15 17:08:59,907 - ==> Confusion:
[[ 253    0    1    0    2    0    0    0    2   44    0    0    1    2    0    1    1    0    0    0    5]
 [   0  240    3    1   10   21    0    5    9    2   35    0    1    7    9    0    5    0   13    0   12]
 [   7    0  267    6    3    5    9   15    0    8   11    0    2    3    0    0    0    0    0    4    5]
 [   0    5   15  238    1   10    1    2    0    2   14    0    2    0   16    3    0    6    8    1    4]
 [  12    0    1    0  332    2    0    0    0    6    1    0    0    5    1    7    4    1    0    0    4]
 [   6   19    3    4    4  201    0   19    2    2    2    0    4   24    8    1    2    0    2    5    9]
 [   0    0   25    1    0    4  286    0    0    0    2    0    1    0    0    5    0    0    0    4    6]
 [   4    3   19    2    2   45    1  252    0    5    6    0    0    0    0    0    0    0   22    6    6]
 [  15    2    1    0    0    1    0    1  287   14    2    0    1    6    9    0    1    1    0    0    6]
 [  72    0    2    0    1    1    1    0    7  251    0    0    0    2    4    2    0    0    0    1    2]
 [   2   22    4    6    9   22    3    3   11    4  249    0    1    1    3    0    1    0   10    1    4]
 [   2    3    3    1    1   17    0    0    1    1    0  177   63   22    0   21    6    9    0   25   14]
 [   2    1    1    7    0   12    0    0    1    2    0   19  228    4    1    8    6   21    0    0    6]
 [   5    4    2    0    8   15    0    1    3   12    4    2    1  239    1    1    4    0    0    3    5]
 [  13    1    0    3    3    3    0    0   32   21    0    0    2    2  244    0    3    3    0    1    8]
 [   4    0    1    3    5    0    4    0    0    2    0    3    2    0    1  330    1    5    0    1    3]
 [   2    1    1    1   11    4    0    0    3    1    0    2    0    7    0    3  328    0    0    0   11]
 [   2    0    1    8    0    1    0    0    1    1    0    1   32    1    9   13    0  266    0    2    7]
 [   2   12    1    6    0    6    0   32    3    1   27    0    0    1    7    0    0    0  252    0    6]
 [   1    1    1    1    0   10    2    7    0    1    2    5    2   10    0    3    2    1    0  288   12]
 [ 140  160   74   84   77  211   14  108   67  169   80   32  133  157  161   37   75   42   75  197 2278]]

2025-08-15 17:09:00,353 - ==> Best [Top1: 66.236   Top5: 93.806   Sparsity:0.00   Params: 126490 on epoch: 3]
2025-08-15 17:09:00,353 - Saving checkpoint to: logs\2025.08.15-162526\checkpoint.pth.tar
2025-08-15 17:09:00,380 - 

2025-08-15 17:09:00,381 - Training epoch: 101719 samples (256 per mini-batch)
2025-08-15 17:11:43,389 - Epoch: [4][  398/  398]    Overall Loss 0.753769    Objective Loss 0.753769    Top1 68.221574    Top5 95.043732    LR 0.001000    Time 0.409546    
2025-08-15 17:11:44,070 - --- validate (epoch=4)-----------
2025-08-15 17:11:44,071 - 11302 samples (256 per mini-batch)
2025-08-15 17:12:15,598 - Epoch: [4][   45/   45]    Loss 0.806880    Top1 65.351265    Top5 93.364006    
2025-08-15 17:12:16,217 - ==> Top1: 65.351    Top5: 93.364    Loss: 0.807

2025-08-15 17:12:16,218 - ==> Confusion:
[[ 251    2    1    0    1    1    0    0   12   36    1    1    0    1    1    1    0    0    0    0    3]
 [   0  290    1    0    5    4    0    1    7    1   44    0    1    2    1    0    7    0    6    0    3]
 [   6    2  250    7    5    3   16   16    0    7   23    0    1    1    0    0    0    1    1    3    3]
 [   1    4    7  245    0    6    0    3    1    2   32    0    0    0   15    0    0    3    6    1    2]
 [   8    3    0    0  339    2    0    0    0    9    5    0    0    0    1    2    5    1    0    0    1]
 [   2   46    1    2    5  165    0   18    6    1   29    2    2   23    7    0    1    0    0    1    6]
 [   0    1   18    2    0    3  287    2    0    1    7    0    0    0    0    2    0    0    0    3    8]
 [   3   17    7    0    0   22    4  266    1    1   26    0    0    2    1    0    0    0   18    1    4]
 [  12    4    0    0    0    0    0    0  312    7    3    0    0    2    3    0    2    0    1    0    1]
 [  42    2    2    0    1    1    1    0   30  253    0    0    0    8    4    0    1    0    0    1    0]
 [   2   14    0    0    7    4    3    1   12    1  298    0    2    2    4    0    1    0    4    0    1]
 [   1    2    2    3    2   18    0    3    1    2    2  232   25   15    0    3   24    8    0   15    8]
 [   1    2    0    5    1    5    0    1    7    2    7   29  201    2    4    5   21   19    1    0    6]
 [   3   11    0    0   12   12    0    0   17    2    8    0    1  229    3    0    7    0    0    2    3]
 [   8    7    0    1    2    2    1    0   42    9    2    0    0    1  254    0    3    2    0    0    5]
 [   2    0    5    4    7    1    3    0    0    2    0    7    1    0    3  310    9    7    0    1    3]
 [   2    5    0    1   10    2    0    0    2    0    0    4    0    2    0    0  342    0    0    0    5]
 [   2    0    1    8    0    0    1    0    4    1    0    2   16    1   13    5    1  281    0    2    7]
 [   2   13    0    3    0    1    1   31    6    1   50    0    0    0    6    0    0    0  236    0    6]
 [   0    3    0    0    0    4    6   11    1    0    5   12    2    9    0    2   10    1    2  271   10]
 [ 124  320   58   51   69  130   25   96  130  172  200   53   95  111  184   16  176   44   68  175 2074]]

2025-08-15 17:12:16,961 - ==> Best [Top1: 66.236   Top5: 93.806   Sparsity:0.00   Params: 126490 on epoch: 3]
2025-08-15 17:12:16,962 - Saving checkpoint to: logs\2025.08.15-162526\checkpoint.pth.tar
2025-08-15 17:12:16,968 - --- test ---------------------
2025-08-15 17:12:16,969 - 13430 samples (256 per mini-batch)
2025-08-15 17:12:37,458 - Test: [   53/   53]    Loss 0.819688    Top1 65.256888    Top5 93.246463    
2025-08-15 17:12:38,096 - ==> Top1: 65.257    Top5: 93.246    Loss: 0.820

2025-08-15 17:12:38,097 - ==> Confusion:
[[ 311    2    0    0    4    2    0    0   12   50    1    0    0    3    4    0    0    2    0    0    3]
 [   1  329    0    1    3    5    0    5   16    0   43    0    1    2    2    0    1    0    5    1    3]
 [   7    2  299    8   10    3   11   16    1   10   26    1    0    4    2    3    0    3    1    0   10]
 [   6    1    6  285    1    4    2    1    7    3   36    1    0    0   26    0    1    5    6    0    1]
 [   9    4    1    1  358    3    0    0    4    8    4    0    0    3    3    0    3    0    0    0    4]
 [   0   66    0    3    4  245    3   21    5    6   34    5    1   22    5    0    2    0    4    3    3]
 [   0    2   15    2    1    1  390    8    1    1   11    0    0    1    0    1    0    1    1    0    5]
 [   0   14    6    1    1   37    3  286    2    1   41    1    0    3    1    0    0    0   24    2    4]
 [   8    7    0    0    0    0    0    0  366   11    5    0    0    4    8    0    1    1    0    0    1]
 [  41    1    2    0    4    0    0    0   25  298    1    2    0    9    4    1    1    0    0    0    3]
 [   4   25    1    4    2    6    1    5    8    1  359    0    0    0    4    0    2    0    6    1    2]
 [   0    1    0    1    2   17    4    3    1    3    3  278   37   24    0    6   20    8    0   20    3]
 [   2    4    0    5    2    3    0    2    7    0    2   40  271    3    9    1   22   22    2    0    8]
 [   4    7    0    0    6   26    0    1   14    9    3    6    0  289    8    0   20    2    0    1    5]
 [   8    5    0    2    3    1    0    1   61   10    1    0    0    1  341    1    1    0    1    0    2]
 [   3    1    0    5    6    4    4    0    0    2    0    2    4    0    2  364    7    9    0    2    6]
 [   2   14    1    0    8    0    0    0   11    1    3    5    1    3    1    2  386    1    0    0    6]
 [   4    2    1    5    0    2    0    0   12    1    0    7   20    0    9    5    4  319    1    0   10]
 [   0   23    3   14    0    5    2   26    9    2   72    0    2    0    7    0    0    0  264    0    4]
 [   0    3    1    1    0    8    3   13    1    2    6   16    2    7    0    2    8    2    0  367    4]
 [ 153  354   60   69   81  131   35  112  138  197  246   48  105  175  190   26  248   50   64  205 2359]]

2025-08-15 17:12:38,536 - 
2025-08-15 17:12:38,536 - Log file for this run: D:\B_School\School\TestMax\ai8x-training\logs\2025.08.15-162526\2025.08.15-162526.log
